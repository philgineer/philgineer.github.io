<h1 id="-4-02-16-">피어세션기록(4주차, 02.16 화)</h1>
<h2 id="-">오늘 수업/실습/과제</h2>
<ul>
<li>further question<ul>
<li>BPTT 이외에 RNN/LSTM/GRU의 구조를 유지하면서 gradient vanishing/exploding 문제를 완화할 수 있는 방법이 있을까요?<ul>
<li>(준호) 그냥 ReLU쓰면 되는거 아닌가요?</li>
<li>(준배) Gradient Clipping : 기울기가 임계값을 넘어가면 자르기, 배치 정규화<ul>
<li>미니배치랑 배치정규화랑은 다른 개념</li>
</ul>
</li>
</ul>
</li>
<li>RNN/LSTM/GRU 기반의 Language Model에서 초반 time step의 정보를 전달하기 어려운 점을 완화할 수 있는 방법이 있을까요?<ul>
<li>(준호) 그럼 Transformer는 이 문제를 해결한건가요?<ul>
<li>한번에 모든 단어를 다 집어넣다보니 해결한거같은데..</li>
</ul>
</li>
<li>Gradient Vanishing과 Exploding을 해결했다고 해서 long term dependency를 해결한 건 아니다?</li>
<li>(지원) Skip connection을 사용하는건 어떨까요?<ul>
<li>(준호) 그건 CNN에서라서 특이했던 방법같은데, hidden state나 cell state를 가져와서 합치는게 어떨까 싶네요.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="-">마스터클래스 질문 준비</h2>
<ul>
<li>NLP<ul>
<li>[x] NLP를 연구하는 데에 있어서 언어학 도메인지식이 어느정도 필요하다고 보시나요?<ul>
<li>언어학자를 해고할수록 자연어처리 모델 성능이 향상되었다는 일화를 들은 적이 있었는데, 요즘에도 NLP 분야에서 언어학 도메인 지식이 별로 중요하게 취급되지 않나요?</li>
</ul>
</li>
<li>--NLP가 다른 딥러닝 영역과 가장 크게 차이있는 것이 한가지 있다면 무엇일까요? 또, 그 차이점으로 인해 NLP가 어느 분야에 적용될 수 있다고 전망하시나요?</li>
<li>--AI 스타트업은 처음부터 기술력을 많이 모아서 시작하나요?<ul>
<li>대기업은 모르겠는데 스타트업이 오히려 더 능력있는 사람이 많았던것같음.</li>
</ul>
</li>
</ul>
</li>
<li>--포트폴리오용으로 할 수 있는 ML/DL 개발은 무엇부터 시작하면 될것같은가요?</li>
<li>--교수님이 여기서 study하신다면 뭘 study 하실 것 같으신지?</li>
<li>--Stargan만드신 최윤제님은 지도하실때 어떤 학생이었나요?<ul>
<li>또는, 인상깊었던 학생이 있을까요?</li>
</ul>
</li>
<li>--교수님이 생각하는 좋은 개발자는?</li>
<li>트렌드<ul>
<li>[x] 상용화된 분야를 제외하고, 교수님이 개인적으로 주목하고계신 NLP 분야와 적용 영역이 있을까요?</li>
<li>--반도체 공정 분야에 적용되는 AI 트렌드는 무엇이 있을까요?</li>
<li>--프론트엔드 분야에 AI가 접목되어서 어떻게 바뀔 수 있을까요?</li>
<li>--transformer가 나온 뒤 필요한 데이터가 너무 많아져서 대형회사가 아니면 GPU 리소스를 구하기 힘들다고 하셨는데, 이에 대한 해결책으로 연구되고 있는 것들이 있을까요?</li>
<li>--Federated Learning의 전망에 대해서 생각하고 계신 바가 궁금합니다.</li>
</ul>
</li>
</ul>
