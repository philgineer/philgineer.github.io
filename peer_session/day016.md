# 피어세션기록(4주차, 02.15 월)

## 오늘 수업/실습/과제

* 질문
    * (성익) Word2Vec에서 히든 레이어의 수는 정해져있는건가요? 좌표공간 차원수는 원-핫벡터 크기 아닌가요?
        * (준호) hidden layer의 노드 수는 하이퍼파라미터라 관계없다. 그냥 feature의 차원 수
        * (지원) 좌표 공간 차원수는 feature 수이고, 이건 원-핫벡터 사이즈랑 관계없음.
    
    * (성익) class와 label 차이?
        * (준배) 클래스는 일종의 카테고리, lable은 데이터에 대한 값
        * (준호) 레이블링은 지도학습을 위한 ground truth를 지정해주는것이니까.. 데이터에 대한 classification 값이 label.
    
    * (성익) Word2Vec에서 Input vector와 output vector가 같다는게 무슨말인가요?
        * (지원) Word embedding은 거리를 기준으로 관계도만 측정하는거기 때문에, Input vector만 사용하든 Output vector만 사용하든 상관없다.
    
    * (현우) 원-핫벡터에서 dimension이 뭔가요? 그냥 1차원 벡터아닌가요?
        * (성익) 원-핫벡터는 컴퓨터가 알아듣도록 만드는 1차원 array일 뿐이고, 실제 의미는 공간좌표에서 해당 단어(점)의 위치.
        * (준호) hidden layer에서 feature dimension과 같은 맥락.
        * (지원) tensor에서의 괄호랑은 다른거죠?
            * (성익) 저는 비슷하게 생각했는데, tensor도 결국 공간좌표상의 여러 점들을 모아놓은것 아닌가요?
            * (준호) 원-핫 벡터의 차원이랑은 다른 느낌이긴 한거 같아요.
    
    * (성익) Loss Function, Cost Function, Objective Function 차이?
        * Loss는 하나의 데이터 포인트에 대해, Cost는 전체 데이터셋에 대한 Cost.
        * Objective는 머신러닝 이외에도 사용하는, 목적을 이루기 위한 함수식. 딥러닝에서는 Cost Function과 비슷하게 사용되는듯
        * (머신러닝 - Loss Function, Cost Function, Objective Function의 차이)[http://blog.naver.com/PostView.nhn?blogId=qbxlvnf11&logNo=221386278997&parentCategoryNo=&categoryNo=&viewDate=&isShowPopularPosts=false&from=postView]
    
    * (성익) 역전파 과정 설명?
        * (준호) [cs-231n](http://blog.naver.com/PostView.nhn?blogId=qbxlvnf11&logNo=221386278997&parentCategoryNo=&categoryNo=&viewDate=&isShowPopularPosts=false&from=postView)
        * (지원) [cs-231n 강의노트](https://cs231n.github.io/optimization-2/)

* 이번주는 실습 위주라서, 실습을 좀 빡세게 잡는게 좋을듯.

* (futher question)Word2Vec과 GloVe 알고리즘이 가지고 있는 단점은 무엇일까요?
    * (성익) 단락의 양이 많아지거나 하면, 멀리 있는 것과의 연관성이 없을것같다.
    * (준호) 순서를 파악하지 못할 것 같다.
    * GloVe의 문제점
        * (현우) 윈도우를 크게 잡아서 한번에 다 count해야 해서 리소스가 많이 든다.
    * (준호) Word2Vec은 주어진 윈도우 안에서 학습 예측을 다 하는거고.
    * (준호) GloVe 윈도우 사이즈는 중요하지 않고, 사전 통계를 만들어 놓고 새로운 단어를 추측하는것.
    * [GloVe 구현 코드](https://lovit.github.io/nlp/representation/2018/09/05/glove/)


## 정보

* (준호) 파이토치 단어임베딩 튜토리얼(https://tutorials.pytorch.kr/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py)

