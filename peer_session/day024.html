<h1 id="-5-02-25-">피어세션기록(5주차, 02.25 목)</h1>
<h2 id="-">오늘 수업/실습/과제</h2>
<h3 id="-">질문</h3>
<ul>
<li><p>(현우) $\Vert$은 노름인데, |은 어떤 의미?</p>
<ul>
<li>(지원) 개수입니다</li>
<li>혹시 그럼 $\sum 1$은 어떤 의미인가요?<ul>
<li>(준배) 겹치는 원소의 개수를 세겠다는 의미(원소 1개마다 1)</li>
</ul>
</li>
</ul>
</li>
<li><p>(준배) 정점표현학습 전체적 개념</p>
<ul>
<li>그래프의 정점들을 벡터로 표현하는 것을 정점 임베딩이라고 하잖아요.</li>
<li>기존의 ML 도구들을 사용할 수 있게 만들기 위해서 정점 임베딩을 하는거죠.</li>
<li>그런데 &quot;어떤 기준으로 정점을 벡터로 변환해야하는가?&quot;가 목표라고 하는데<ul>
<li>&quot;유사도를 보존하도록 정점 임베딩을 학습&quot;하는 단계란게 정확히 어떤 의미를 가지는 어구죠?</li>
<li>인접성 기반 접근법에서.. 0과 1이 간선인데 그럼 이걸 왜 학습하는거죠? 무조건 0 또는 1아닌가요?</li>
</ul>
</li>
<li>(성익) 그래프에서의 유사도는 그렇게 나오는데, 임베딩 벡터들의 곱은 0이냐 1이냐를 모르기때문에(간선 추정) 임베딩 벡터를 잘 학습시켜서 비슷한 매트릭스를 만들어내는 게 목적입니다.</li>
<li>(성익) 정점표현학습이란, 노드임베딩 과정을 learning하는것.</li>
<li>(지원) 변환식 정점표현학습은 정확히 말하면 벡터 자체를 직접 학습시키는것같아요. 인코더가 아니라. 노드임베딩 과정이 아니라 노드임베딩 값 자체를 학습시키는겁니다.</li>
</ul>
</li>
<li><p>(준호) $R^d$에서 d에 대한 언급이 있었나요?</p>
<ul>
<li>노드가 많으면 노드 갯수를 d 대신 써도 유사도를 충분히 표현할 수 있지만, 너무 벡터가 커진다.</li>
<li>그래서 벡터를 좀 줄여서 유사도를 표현하려고 한다.(일종의 feature개념. 차원을 한정시키는 개념이네요.)</li>
<li>(현우) 실습보면 차원을 정해두고 하는데, 아마도 차원을 한정해두는 개념이 맞는거같아요.</li>
<li>(지원) 단어임베딩에서 차원을 정해두는것도 비슷하지 않을까 싶네요.</li>
<li>(현우) 유사도를 보존할 수 있는 한 차원을 축소시키는 것과 비슷한거같네요.</li>
</ul>
</li>
<li><p>(지원) 임의보행에서 P에 exp가 왜 나오나요?</p>
<ul>
<li>(준호) 유사도값이 -가 나올수 있어서, 정규화를 해서 0부터 1사이의 값으로 만들어준다.</li>
<li>만약 극단적으로 유사도값이 대부분 -가 나와버리면, loss가 -가 되어버리지 않을까요?</li>
<li>(지원) 다항분류할때 비슷한 내용이 나왔던것 같습니다</li>
</ul>
</li>
<li><p>(성익) 경로기반 접근법에서, 왜 A^k가 경로중 k인것의 거리가 되나요?</p>
<ul>
<li>경로 != 최단경로군요.. ㅠㅠ 이해했습니다.</li>
<li>(현우) 그럼 k는 하이퍼파라미터인가요?<ul>
<li>(준호) k는 (최대) 지름일거같아요.</li>
<li>시그마도 들어가야할까요?</li>
<li>(지원) A를 k번 곱하면 k이하인 경우의 수가 다 나오기때문에 안곱해도 될것같아요.</li>
</ul>
</li>
</ul>
</li>
<li><p>(성익) Cluster와 Community의 차이?</p>
<ul>
<li>Cluster를 좌표공간하에 있는 벡터들의 군집, Community를 임베딩 이전의 그래프이론에서의 군집으로 표현하는건가요?</li>
<li>(준호) 클러스터는 엣지가 없는 단순한 벡터들의 군집이 아닐까 싶습니다.</li>
<li>실습의 n-clustering이 그 K네요!<ul>
<li>(지원)<a href="https://ratsgo.github.io/machine%20learning/2017/04/16/clustering/">클러스터링의 종류</a></li>
</ul>
</li>
</ul>
</li>
<li><p>(지원) 중첩 기반 접근법이 거리기반 보다 좋은건가요?</p>
<ul>
<li>보완하는 방식의 느낌으로 더 좋은거같긴해요.</li>
</ul>
</li>
</ul>
<h3 id="further-question">further question</h3>
<ul>
<li><p>추천시스템의 성능을 측정하는 metric이 RMSE라는 것은 예상 평점이 높은 상품과 낮은 상품에 동일한 페널티를 부여한다는 것을 뜻합니다. 하지만 실제로 추천시스템에서는 내가 좋아할 것 같은 상품을 추천해주는것, 즉 예상 평점이 높은 상품을 잘 맞추는것이 중요합니다. 이를 고려하여 성능을 측정하기 위해서는 어떻게 해야 할까요?</p>
<ul>
<li>(준호) 정밀도와 재현율 개념중에 정밀도 개념을 쓰는게 좋지 않을까요?</li>
<li>(현우,준호) 예상평점보다 실제평점에 낮은것에 페널티를 덜주고, 예상평점보다 실제 평점이 높은 것에 페널티를 더주기.</li>
<li>(준호) threshold를 넣어서 특정 값 이상에만 작동하도록?<ul>
<li>(준호, 성익) 두가지 식으로 나누어서, a 와 1-a로 나누어서 비율 조정</li>
<li>(지원) 음수일때 특정 값을 더 곱해주어서 오차값을 높인다.</li>
<li>오차에 방향 바뀐 leacky-relu같은거 곱해주면 될거같아요.</li>
</ul>
</li>
</ul>
</li>
<li><p>추천 시스템의 성능을 향상시키기 위해서는 어떠한 것을 더 고려할 수 있을까요? (해당 문제는 정답이 제공되지 않는 문제입니다. 자유롭게 여러분의 의견을 이야기해보세요.)</p>
<ul>
<li>(현우) 역시 앙상블인가요 ㅎㅎ</li>
<li>(준배) 지속적 피드백을 받는다 - 영화를 안보면 피드백이 안가니까... <ul>
<li>보고싶지 않아요 버튼 - 광고까지 개인맞춤화 할 수 있어요!</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="-">정보 공유</h2>
<ul>
<li><p>(준호) 코세라 머신러닝에 K-means 설명 잘되어 있음</p>
<ul>
<li>K가 하이퍼파라미터라서, 클러스터의 개수를 잘못 예측했을 경우 학습이 잘 안되는 단점이 있다.</li>
<li>랜덤으로 뿌리고, loss를 최적화해가면서 뭉치게 만드는 것</li>
<li>K-means는 사실 옛날거고, 최근에는 K를 지정해주지 않아도 되는 비지도 학습이 많이 나온거같아요.</li>
</ul>
</li>
<li><p>(준호) 단단한 머신러닝 클러스터링 정리한 내용 공유</p>
<ul>
<li>외부/내부 지표도 따로 있고, 거리 측정하는 방식도 아주 다양함.</li>
</ul>
</li>
</ul>
