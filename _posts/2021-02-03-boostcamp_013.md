---
title: "Boostcamp AI Tech (Day 013)"
date: 2021-02-03
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

My assignment: [CNN pytorch](https://colab.research.google.com/drive/1asdfNspJaUs4GJfBepPcg74mpnARceAs?usp=sharing)
<br>

## 1. CNN (Convolutional Neural Networks)

* ### 2D image convolution
    * $(I * K)(i,j) = \sum_m \sum_n I(m,n) K(i - m, j- n)$

        $= \sum_m \sum_n I(i-m,i-n) K(m,n)$

    * $I$: image space, $K$: kernel (convolution filter)
* ### RGB image convolution
    * (filter) * (image) = (feature)
        * $(5 \times 5 \times 3) * (32 \times 32 \times 3) = (28 \times 28 \times 1)$
    * 4 filters
        * $((5 \times 5 \times 3) \times 4 ) * (32 \times 32 \times 3) = (28 \times 28 \times 4)$
* ### 구성
    * convolution layer
        * feature extraction
    * pooling layer
        * feature extraction
    * fully connected layer
        * decision making (ex. classification)
* ### parameter 개수 계산
    * kernel size $\times$ input channel $\times$ output channel(kernel 개수)
* ### 1 $\times$ 1 convolution
    * dimention reduction
    * parameter 수 감소 (depth가 증가함에도)
    * ex. bottleneck architecture
<br><br>

## 2. Modern CNN

* ### AlexNet (2012)
    * ILSVRC (Imagenet Large-Scale Visual Recognition Challenge)
        * classification, detection, localization, segmentation
    * GPU 연산 한계로 2 트랙으로 설계됨
    * 최대 11 $\times$ 11 filter 사용 (파라미터 수 급증)
    * ReLU 사용
        * preserve properties of linear models
        * easy to optimize with gradient descent
        * good generalization
        * overcome the vanishing gradient problem
    * GPU (2개) 활용
    * local response normalization, overlapping pooling 사용
    * data augmentation 사용
    * dropout 사용
    * 당시에는 흔하지 않은 방법들이었음 (하나의 기준이 됨)
* ### VGGNet
    * 3 $\times$ 3 filter만 사용해 depth를 늘림
        * 5 $\times$ 5 한 번보다, 3 $\times$ 3 두 번이 사용하는 파라미터 수가 더 적음
    * 1 $\times$ 1 for FC Layer, dropout 사용
* ### GoogeLeNet (2015)
    * NIN (Network in network) 구조
    * Inception blocks
        * 하나의 입력에 대해 여러 개의 receptive field를 갖는 filter를 거쳐 여러 개의 response를 concate하는 효과
        * 1 $\times$ 1 convolution이 중간에 끼어들어감으로서 파라미터 수 감소
    * 1 $\times$ 1 convolution
        * channel-wise dimension reduction

            ||3 $\times$ 3|(1 $\times$ 1) and then (3 $\times$ 3)|
            |---|---|---|
            |params|3 $\times$ 3 $\times$ 128 $\times$ 128|(1 $\times$ 1 $\times$ 128 $\times$ 32) + (3 $\times$ 3 $\times$ 32 $\times$ 128)|
            |total|= 147456|= 40960|

    * AlexNet, VGGNet에 비해 파라미터 수 비약적으로 감소 (60M, 110M -> 4M)
* ### ResNet (2015)
    * Identity map (residual connection, skip-connection) 추가
        * $f(x) \rightarrow x + f(x)$
        * input x항을 출력값에 추가해줌으로서, residual 즉 **차이**만 학습시킴
    * network를 deep하게 쌓을 수 있는 가능성을 열어줌
    * bottleneck architecture: 1 $\times$ 1 $\rightarrow$ 3 $\times$ 3 $\rightarrow$ 1 $\times$ 1
* ### DenseNet
    * 다음 두 블록을 반복해가며 학습
    * Dense block
        * residual을 더하지 말고, concatenation 해줌
        * 대신 채널 수가 계속 증가함
    * Transition block
        * batch norm $\rightarrow$ 1 $\times$ 1 Conv $\rightarrow$ 2 $\times$ 2 AvgPooling
        * demention reduction
<br><br>

## 3. Computer vision applications

* ### Semantic segmentation
    * dense / per pixel classification
    * 자율주행에 활용
    * convolutionization
        * flatten layer 없이 conv 연산으로 label vector 계산
        * 파라미터 개수는 기존 flatten 후 label과 동일
        * heat map 생성 가능
    * fully convolutional network
        * output dimensions reduced by subsampling
        * upsampling을 통해 다시 output 사이즈 키워줌
        * padding을 적절히 줘서 deconvolution을 사용해 upsample
* ### Detection
    * R-CNN
        * Extract region proposals with Selective search (2000개 이하)
        * Compute CNN features for each proposal with AlexNet
        * classify with linear SVM
    * SPPNet
        * R-CNN과 같지만, bounding box에 해당하는 텐서만 떼와서 학습 (CNN을 2000번이 아닌 1번 돌림)
    * Fast R-CNN
        * SPPNet과 거의 비슷하지만, 뒷단에 neural net (ROI feature vector 단)이 쓰임
    * Faster R-CNN
        * region proposal, 즉 bounding box를 뽑는 것도 학습으로 해결
        * R-CNN + RPN
        * RPN(Region proposal network)
        * anchor box: 미리 정해 둔 bounding box의 크기 (템플릿). detection box with predefined sizes
        * fully conv: (3 region sizes * 3 ratios) * (4 bounding box params + 2 box classification(yes/no)) = 54
    * YOLO (v1)
        * You Only Look Once: 이미지 한 장에서 바로 output 출력
        * Faster R-CNN보다 훨씬 빠름 (바운딩 박스 찾는 것과 클래스 찾는 것을 2트랙으로 동시에 진행)
        * no explicit bounding box sampling
        * output tensor: (그리드의 셀 개수) * (바운딩박스 offset 5개 + 클래스 개수)
<br><br>