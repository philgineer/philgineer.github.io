---
title: "Boostcamp AI Tech (Day 036)"
date: 2021-03-15
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

[![Peer Session Badge](https://img.shields.io/badge/Peer%20Session-CC527A?style=flat)](../peer_session/day036.html)

My assignment: [탐색적 데이터 분석 (landmark data)](https://colab.research.google.com/drive/1ii299ZywMAQyiSH20AS2zfSNgGKHomrZ?usp=sharing)

## Lightweight models
* ### Decision making
    * 연역적(deductive) 결정
    * 귀납적(inductive) 결정
        * data ($\rightarrow$ training) ($\rightarrow$ compression) $\rightarrow$ inference
* ### Decision making machine
    * 평균(mean)
        * 가장 나이브한 머신러닝 모델
        * (70,80,90) not decided $\rightarrow$ 80 decided
        * $\Leftrightarrow$ model(data) $\rightarrow$ "cat"
    * 분류기(classifier)
* ### Lightweight (경량화)
    * 학습시킨 큰 모델을 작게 compress
    * TinyML
* ### Keywords
    * Backbnone & dataset for model compression
    * Edge device
        * dumb and fast
    * Edge intelligence
        * edge training
        * **edge inference**
        * edge offloading
        * edge caching
<br><br>

## Optimization
* ### Optimization & Decision
    * Optimization problem
        * MST, HamCyc, MVC
        * decision problem을 여러 번 반복하며 근사, 귀납
    * Decision problem
        * DST, DHamCyc, DVC
        * Yes / No
    * [참고 자료(알고리즘)](https://courses.helsinki.fi/sites/default/files/course-material/4597051/DAA-lecture5.pdf)
* ### Constraints
    * Objective: maximize performance while $Cost_1 + Cost_2 + ... \leq Constraint^*$
* ### Model compression
    * objective: performance
    * constraints: costs
<br><br>