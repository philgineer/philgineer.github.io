---
title: "Boostcamp AI Tech (P1 - Day08)"
date: 2021-04-07
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

## 개인 Project 진행 상황
* ### 목표치 f1 score 0.7 달성!!
    * 학습 결과 4 참고
* ### 학습 결과 1
    * EfficientNet b2
    * Best validation Acc: 0.51
    * Test f1 score: 0.6674 (지난 주 최고 기록 0.66)
    * Hyper param
        * optim: AdamW
        * loss: CE
        * lr: 1e-4
        * lr scheduler
            * stepsize: 3
            * gamma: 0.2
        * batchsize: 128
        * transform
            * grayscale (val, test 에도 적용)
            * random rotation(10)
            * centercrop(450, 360)
            * horizontal flip
            * resize(200, 200)
            * normalize
* ### 학습 결과 2
    * EfficientNet b2
    * Best validation Acc: 0.56
    * Test f1 score: 0.6780
    * Hyper param
        * optim: AdamW
        * loss: Focal loss (gamma: 1)
        * lr: 3e-4
        * lr scheduler, transform, batchsize 그대로
 * ### 학습 결과 3
    * EfficientNet b3
    * Best validation Acc: 관측 불가
    * Test f1 score: 0.7171
    * Hyper param
        * optim: AdamW
        * loss: Focal loss (gamma: 1)
        * lr: 3e-4
        * no validation set (all train), epoch 4
 * ### 학습 결과 4
    * EfficientNet b4
    * Best validation Acc: 관측 불가
    * **Test f1 score: 0.7235** (최고 기록)
    * Hyper param
        * optim: AdamW
        * loss: Focal loss (gamma: 0.8)
        * lr: 3e-4
        * no validation set (all train), epoch 4
        * grayscale, horizontal flip 없앰
<br><br>

## Peer session
* mixed prisicion
    * float32 (32bit) 보다 float16 (16bit) 으로 계산시 훨씬 빠르지만, 정확도 손실이 있음. 이를 보완하기 위해 빠르면서도 필요한 정보를 거의 보존하는 방법으로, 16bit와 32bit를 적절히 사용한 mixed precision 방법이 있음.
<br><br>