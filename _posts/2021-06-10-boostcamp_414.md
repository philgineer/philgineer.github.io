---
title: "Boostcamp AI Tech (P4 - Day14)"
date: 2021-06-10
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

## Peer session

### 한 일
- 임기홍
    - H//2 학습 다시 학습 하니까 왜 잘나오지..?
    - satrn train_data inference(무슨 inference가 5시간이나 걸림?)
        - ![](https://i.imgur.com/Z42yZql.png)
        - Error Analysis
            - 문제파악을 좀 정확하게 해보고싶었음...
        - 모델 학습 완료 후 inference(일단 trainset) 결과를 분석 하려고 EDA 비슷한거 작성중...

- 김현우
    - 준배님 코드 + adamw, 가로 -> 세로, rotate  : 성능이 잘 안 나옴
    - 77 에폭 Validation sentence 0.6363 
    - <img src = "https://i.imgur.com/wm5omED.png"  width="300" height="200">

- 서준배
    - 시각화 해봤는데 이상하게 출력
        - <img src="https://user-images.githubusercontent.com/24247768/121485128-de1f2980-ca0a-11eb-9b06-83fc53056a4c.png" width="300" height="100">
        - 코드가 잘못된듯...


 - 배철환
     - CSTR 사망
         - 채널을 2배로 늘렸는데, 즉 파라미터 수가 2배로 늘렸지만 오히려 안늘릴때보다도 동일 에폭에서 성능 하락
         - 더 웃긴건 train도 같이 하락
         - 왜?
             - 애초에 CNN의 한계인가? 싶기도 함
             - 정말로 문장의 길이 수에 비례한다면, 2배를 늘렸을 때 조금이라도 잘 되었어야 했다
             - 근데 아닌 걸로 봐서는 아무리 CNN단에서 attention을 걸어준다 해도 transformer를 이길 수는 없는듯
             - 그런데 왜 저번에 SRN은 성능이 안나왔던거지??????
        - 결론
            - ~~트랜스포머 개쎄다.. 안깝쳐야지~~
            - SOTA라고 다 좋진 않구나..!
    - 그래서 SATRN로 빤스런
        - 지금 시점에서 할 수 있는거는 그나마 Backbone을 잘 바꾸는 거 밖에 없다고 판단, efficientnet v2 + FPN으로 바꾸고 학습 시도 중 + 공지에서 코드 수정하는거 포함 + 이미지 binarization


 - 조호성
     - SATRN adaptive + localfeed + deformable로 학습중
     - Aster 학습중 (ResNet기반에 인코더 LSTM추가. 망하는중)
     - SEED는 pretrained된 모델이 없는거 같아서 못 적용할듯
     - BeamSearch 찾아보는중 


- 윤준호
    - SATRN adaptivePE + input_size(128,256) + CNNdepth32 학습 중
        - TransformerDecoder code 수정 후 다시 학습 중
        - 첫 50에폭은 cycle scheduler로 돌린 후 cosine annealing으로 변경 예정
        - augmentation 없이 준배님 학습 잘 되는 거 보고, rotate & sheer & affine & colorjitter 모두 값 반으로 줄임 (augmentation 축소)


### 정리
- adaptivePE
    - ![image](https://user-images.githubusercontent.com/24247768/121486265-f479b500-ca0b-11eb-8d0e-f9ee4faa173d.png)


### 발표 자료

height(하이트🍺) - 배워갑니다..
weight(웨이트)

- 조원 소개
    - 그냥 페이지만 말은 대충건너뛰기?
- 협업 (강조해야 함)
    - ConnectNet 팀의 최대 장점!!! 
        - hackmd로 회의록 작성
        - 엑셀 실험 정리
        - slack DM방
    - 이름부터 connect net
- OCR 배경 지식 (과연 필요할까?)
- 문제해결 접근 방식 
    - 문제 정의(했나?)
    - 문제 접근
    - 문제 해결 결과
- 수학은 어디에(??): 모든 곳에 조금씩
    - 갓기홍님 활용해야 됨
    - EDA 분석할 때? 
- 데이터 EDA + Error EDA
    - 예쁘게 + 
    - cycle scheduler로 인한 50에폭에서 재학습시 급격한 성능 감소 (후보로만...)
        - WHY?
- 최종 리더보드 점수를 얻기까지 직접적으로 시도 한 것들
    - AdaptivePE
    - GRU
    - CNN dense block 튜닝
        - deformable CNN
        - layer depth 16 -> 32
    - Augmentation
    - 세로 이미지 -> 가로로 돌리기
    - image Binarization (Adaptive Threshold)
- 성능을 향상시키지는 못했지만 의미 있었던 시도들
    - 모델 탄생과 죽음(시도한 것,성능 향상과정)
    - 학습이 어느 정도 진행된 후에 teacher forching rate 낮추기
- Time Table (좋아용)
    - 1주,2주,3주까지의 여정

- 발표는 누가? (어렵네요...)
    - 역시 E!!! 
    - 준배님!!!
        - ???
        - INT
        - INFJ...
        - ISTJ ...
      
      
- 노션을 먼저 작성해야 함

- github readme 정리
- PPT
    - 운영진에 양식을 받아서 사용

- 금요일 발표순서 추첨한다고 합니다.
    - 먼저하면 신선
        - 뒤로갈수록 비슷한 내용이 나올거에요 아마도
    - 마지막이 젤 좋다
        - 인상을 줄수있따.
        - 너무 늦으면....
    - 담당자가 중간에 올 수 있음
    - 모든 건 운 빨
    - 만약에 선택권이 있다면 앞뒤로 2 ~3번째가 제일 좋음
- 부스 운영은 어떻게 해야 할까?
    - 아 .. 네.. 노노
    - 피피티 붙여넣기
    - 만약에 영상을 만들 수 있다면 영상 틀어 놓기 ㅋㅋ 질의 응답 받기 
    - DM 으로 대기 
    - 챗봇 마렵다.. 일주일 동안 챗봇 만들기  -> 이건 OCR 프로젝트일까 귀차니즘 피하는 프로젝트 일까 
    - 발표는 대회에 참여한 기업들이 홍보용으로만 하고
    - 남은시간은 부스에 우리가 대기하고, 사람들이 돌앋다니면서 질문
        - 기업들이 많이 와서 질문하나요?
        - 한시간만 운영하여, 6 ~ 7팀이 방문하였음 
    - 기업들이 부스만들고 우리가 돌아가면서 기업에게 질문(선물받기)