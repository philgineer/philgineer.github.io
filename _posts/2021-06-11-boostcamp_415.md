---
title: "Boostcamp AI Tech (P4 - Day15)"
date: 2021-06-11
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

## Peer session

# 6ì›” 11ì¼

### í•œì¼

- ê¹€í˜„ìš°
    - ëª¨ë¸ í•™ìŠµ í›„ inference ì—ì„œ ë³€ê²½ëœ ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì´ ë‚®ê²Œ ë‚˜ì˜´ (0.2 ã… ã… ğŸ˜¥)
    - ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œ í›„ ë‹¤ì‹œ inference ì‹œë„
    - flask ì›¹ì„œë²„ êµ¬ë™ í™•ì¸ -> tensorboard ìš© í¬íŠ¸ê°€ ì—´ë ¤ ìˆì–´ ì›¹ì„œë²„ ì‚¬ìš© ê°€ëŠ¥ 
    - flask ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì–´ë–»ê²Œ í™•ë³´í• ê¹Œ? ì´ë¯¸ì§€ ìº¡ì³? ì•„ë‹ˆë©´ ì´ë¯¸ì§€ ì´¬ì˜??? ì‹œì¥ì—ì„œëŠ” ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•´ì•¼ ìƒí’ˆì„±ì´ ìˆì–´ ë³´ì´ë ¤ë‚­
    - ì•ˆë“œë¡œì´ë“œ ì–´í”Œ ì‚¬ì§„ ì´¬ì˜ í›„ ì„œë²„ë¡œ ì „ì†¡í•˜ì—¬ í™•ì¸í• ê¹Œ? ì¼ë‹¨ ì›¹ì„œë²„ê±° ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ í›„ ìƒê° 

- ì„œì¤€ë°°
    - í•™ìŠµ ì§„í–‰ì¤‘
        - 100ìœ¼ë¡œí–ˆëŠ”ë° í‰ë²”...
        - ìŠ¤ì¼€ì¤„ëŸ¬ì˜ ì„¸íŒ…ì´ ì¤‘ìš”í•œë“¯
        - 23/100 VSA=0.56527,WER=0.12646
    - ì›¹ì„œë²„ ì‹ ê¸°í•˜ë‹¤

- ë°°ì² í™˜
    - í•™ìŠµ ì¤‘

- ì„ê¸°í™
    - train_37961.jpg ~ train_4XXXX.jpg ì•½ 7000 predict tokenì„ ì™œ ëª» ë°›ì§€..
        - ![](https://i.imgur.com/bWwH0Eu.png)
        - inference.pyì— data ê²½ë¡œë¥¼ train_dataë¡œ ë°”ê¿”ì„œ ì§„í–‰...(ì•½ 5ì‹œê°„ì§œë¦°ë°)
        - ì¼ë‹¨ ê¸°ì¡´ í•™ìŠµ í›„ì— ë‹¤ì‹œ í•´ë³¼ ì˜ˆì •.
    - í•™ìŠµ ì§„í–‰ì¤‘(Adaptive2DPositionEncoder,resize,,,)
    - ğŸ‘©â€ğŸ’»ì¤Œ(ì˜¤í”¼ìŠ¤ ì•„ì›Œ) ì¤Œ(ì¶”ì²¨) ì¤Œ(ë„¤íŠ¸ì›Œí‚¹) ì¤Œ(í•´ì™¸ì¸í„´ì†Œê°œ) ì¤Œ(í”¼ì–´ì„¸ì…˜) 


- ì¡°í˜¸ì„±
    - cycleì„ 1epochì— 3ë²ˆ í•˜ê²Œ í•´ì„œê·¸ëŸ°ê°€? ë¹ ë¥´ê²Œ acc ì˜¬ë¼ê° (cycle step : len(train_loader)//3)ğŸ˜
    - data augumentation ì ìš©í•´ë³´ê¸°. rotate, blur ë“±

```python
class Locality_aware_Feedforward(nn.Module):

    def __init__(self, filter_size=2048, hidden_dim=512, dropout=0.1):
    
        super(Locality_aware_Feedforward, self).__init__()

        self.layers = nn.Sequential(
            nn.Conv2d(hidden_dim, filter_size, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(filter_size),
            nn.ReLU(True),
            nn.Conv2d(filter_size, filter_size, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(filter_size),
            nn.ReLU(True),
            nn.Conv2d(filter_size, hidden_dim, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(True),
        )

    def forward(self, input, size): # (B, HxW, C)
        b,c,h,w = size
        input = input.transpose(1,2).view(b,c,h,w)
        input = self.layers(input) # (B, hidden, h,w)
        input = input.view(b,c,h*w).transpose(1,2)
        return input
        
class TransformerEncoderLayer(nn.Module):
    def __init__(self, input_size, filter_size, head_num, dropout_rate=0.2):
        ...
        ...
        # self.feedforward_layer = Feedforward(
        #     filter_size=filter_size, hidden_dim=input_size
        # )
        self.feedforward_layer = Locality_aware_Feedforward(
            filter_size=filter_size, hidden_dim=input_size
        )
        self.feedforward_norm = nn.LayerNorm(normalized_shape=input_size)

    def forward(self, input, size): # input : (B, HxW, hidden_dim)
        ...
        ...
        out = self.feedforward_norm(ff + out)
        return out
        
class TransformerEncoderFor2DFeatures(nn.Module):
    ...
    ...
    ...
    def forward(self, input): # (b, c, h, w)

        out = self.shallow_cnn(input)  # [b, hidden_dim, h, w]
        out = self.positional_encoding(out)  # [b, hidden_dim, h, w]

        # flatten
        b, c, h, w = out.size()
        out = out.view(b, c, h * w).transpose(1, 2)  # [b, h x w, hidden_dim]

        for layer in self.attention_layers:
            out = layer(out, (b,c,h,w))
        return out
```

- ìœ¤ì¤€í˜¸
    - í•™ìŠµ ì˜ ë˜ëŠ” ì¤‘
        - adaptivePE + input_size, CNN depth & Transformer dimentions ì¦ê°€ íš¨ê³¼ ìˆëŠ” ë“¯
        - ì²« 40 ì—í­ì€ í™•ì‹¤íˆ cycle schedulerê°€ í•™ìŠµ ì˜ í•˜ëŠ” ë“¯.
            - warm-up ë•Œë¬¸ì¼ê¹Œ? cosine annealingì€ ì–´ëŠì •ë„ í•™ìŠµëœ ì´í›„í›„ì—ëŠ” ë” ì˜ë¨

    - ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
        ```python
        class AddGaussianNoise(object):
        def __init__(self, mean=0., std=1.):
            self.std = std
            self.mean = mean

        def __call__(self, tensor):
            return tensor + torch.randn(tensor.size()) * self.std + self.mean

        def __repr__(self):
            return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)
        ```
    

### íšŒê³ 

#### ì˜í•œì¼ğŸ¥‡
- ì—´ì‹¬íˆ ì°¸ì—¬í•˜ê³  ìˆìŒ
- í‹°ì…”ì¸  ì‹ ì²­
- 

#### ì•„ì‰¬ìš´ì¼ğŸ¥ˆ
- ê¸°ë³¸ì— ì¶©ì‹¤í•˜ì§€ ëª»í•¨
- ë” ì‹¤í—˜í•´ë³¼ ì—¬ì§€ê°€ ë§ì€ë“¯í•œë° ì‹œê°„ì´ ì• ë§¤í•´ì„œ ë§ˆë¬´ë¦¬í•™ìŠµì¤‘
- ì‹œê°„ê´€ë¦¬

#### ë„ì „í• ì¼ğŸ…
- ë„¤íŠ¸ì›Œí‚¹ë•Œ ë³´ì—¬ì¤„ ë°ëª¨ê°€ í•„ìš”í•˜ë‹¤
    - dktë‘ ë¹„ìŠ·í•˜ê²Œ
    - í”„ë¡ íŠ¸ë¥¼ ì–´ë–»ê²Œí• ì§€

#### ëŠë‚€ì 
- ì´ì œ ëŒ€íšŒê°€ ë§ˆë¬´ë¦¬ë˜ì–´ê°€ëŠ”ì¤‘ì¸ë° ì•„ì‰½ë‹¤.
- ë­ í•œê±° ì—†ëŠ”ë° ë¶€ìŠ¤íŠ¸ìº í”„ê°€ ëë‚˜ê°„ë‹¤. ë¨¸ë¦¿ì†ì´ ë³µì¡í•˜ë‹¤