---
title: "Boostcamp AI Tech (P4 - Day15)"
date: 2021-06-11
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

## Peer session

# 6월 11일

### 한일

- 김현우
    - 모델 학습 후 inference 에서 변경된 모델을 적용하여 성능이 낮게 나옴 (0.2 ㅠㅠ😥)
    - 모델 학습이 완료 후 다시 inference 시도
    - flask 웹서버 구동 확인 -> tensorboard 용 포트가 열려 있어 웹서버 사용 가능 
    - flask 이미지 데이터는 어떻게 확보할까? 이미지 캡쳐? 아니면 이미지 촬영??? 시장에서는 어떠한 방식으로 진행해야 상품성이 있어 보이려낭
    - 안드로이드 어플 사진 촬영 후 서버로 전송하여 확인할까? 일단 웹서버거 기능 구현 완료 후 생각 

- 서준배
    - 학습 진행중
        - 100으로했는데 평범...
        - 스케줄러의 세팅이 중요한듯
        - 23/100 VSA=0.56527,WER=0.12646
    - 웹서버 신기하다

- 배철환
    - 학습 중

- 임기홍
    - train_37961.jpg ~ train_4XXXX.jpg 약 7000 predict token을 왜 못 받지..
        - ![](https://i.imgur.com/bWwH0Eu.png)
        - inference.py에 data 경로를 train_data로 바꿔서 진행...(약 5시간짜린데)
        - 일단 기존 학습 후에 다시 해볼 예정.
    - 학습 진행중(Adaptive2DPositionEncoder,resize,,,)
    - 👩‍💻줌(오피스 아워) 줌(추첨) 줌(네트워킹) 줌(해외인턴소개) 줌(피어세션) 


- 조호성
    - cycle을 1epoch에 3번 하게 해서그런가? 빠르게 acc 올라감 (cycle step : len(train_loader)//3)😎
    - data augumentation 적용해보기. rotate, blur 등

```python
class Locality_aware_Feedforward(nn.Module):

    def __init__(self, filter_size=2048, hidden_dim=512, dropout=0.1):
    
        super(Locality_aware_Feedforward, self).__init__()

        self.layers = nn.Sequential(
            nn.Conv2d(hidden_dim, filter_size, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(filter_size),
            nn.ReLU(True),
            nn.Conv2d(filter_size, filter_size, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(filter_size),
            nn.ReLU(True),
            nn.Conv2d(filter_size, hidden_dim, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(True),
        )

    def forward(self, input, size): # (B, HxW, C)
        b,c,h,w = size
        input = input.transpose(1,2).view(b,c,h,w)
        input = self.layers(input) # (B, hidden, h,w)
        input = input.view(b,c,h*w).transpose(1,2)
        return input
        
class TransformerEncoderLayer(nn.Module):
    def __init__(self, input_size, filter_size, head_num, dropout_rate=0.2):
        ...
        ...
        # self.feedforward_layer = Feedforward(
        #     filter_size=filter_size, hidden_dim=input_size
        # )
        self.feedforward_layer = Locality_aware_Feedforward(
            filter_size=filter_size, hidden_dim=input_size
        )
        self.feedforward_norm = nn.LayerNorm(normalized_shape=input_size)

    def forward(self, input, size): # input : (B, HxW, hidden_dim)
        ...
        ...
        out = self.feedforward_norm(ff + out)
        return out
        
class TransformerEncoderFor2DFeatures(nn.Module):
    ...
    ...
    ...
    def forward(self, input): # (b, c, h, w)

        out = self.shallow_cnn(input)  # [b, hidden_dim, h, w]
        out = self.positional_encoding(out)  # [b, hidden_dim, h, w]

        # flatten
        b, c, h, w = out.size()
        out = out.view(b, c, h * w).transpose(1, 2)  # [b, h x w, hidden_dim]

        for layer in self.attention_layers:
            out = layer(out, (b,c,h,w))
        return out
```

- 윤준호
    - 학습 잘 되는 중
        - adaptivePE + input_size, CNN depth & Transformer dimentions 증가 효과 있는 듯
        - 첫 40 에폭은 확실히 cycle scheduler가 학습 잘 하는 듯.
            - warm-up 때문일까? cosine annealing은 어느정도 학습된 이후후에는 더 잘됨

    - 가우시안 노이즈
        ```python
        class AddGaussianNoise(object):
        def __init__(self, mean=0., std=1.):
            self.std = std
            self.mean = mean

        def __call__(self, tensor):
            return tensor + torch.randn(tensor.size()) * self.std + self.mean

        def __repr__(self):
            return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)
        ```
    

### 회고

#### 잘한일🥇
- 열심히 참여하고 있음
- 티셔츠 신청
- 

#### 아쉬운일🥈
- 기본에 충실하지 못함
- 더 실험해볼 여지가 많은듯한데 시간이 애매해서 마무리학습중
- 시간관리

#### 도전할일🏅
- 네트워킹때 보여줄 데모가 필요하다
    - dkt랑 비슷하게
    - 프론트를 어떻게할지

#### 느낀점
- 이제 대회가 마무리되어가는중인데 아쉽다.
- 뭐 한거 없는데 부스트캠프가 끝나간다. 머릿속이 복잡하다