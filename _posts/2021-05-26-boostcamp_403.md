---
title: "Boostcamp AI Tech (P4 - Day03)"
date: 2021-05-26
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

## Peer session

### 오늘 한일
- 윤준호 (나)
    - img to latex 논문 읽고 키 포인트 뽑음
        - 이번 대회의 task와 상당히 유사해서 참고할 것이 많음
        - 해당 논문을 구현한 [github repo](https://github.com/guillaumegenthial/im2latex)도 훑어봄
        - 하이퍼파라미터, 아키텍처 등 벤치마킹할 수 있는 요소들이 많음
- 서준배
    - 코드
    - attention기억안나서 강의 다시 확인
- 배철환
    - 어제 실험 진행
        - 생각보다 잘 된다. 다만 에폭이 5라서 아직 확신은 힘듬
    - 제출 막혀서 돌려보지는 않음
    - 코드확인
        - 데이터셋 확인
        - attention 코드도 확인
        - gru셀 안되는것 확인
        - lstm은 잘되는것 확인
        - 내부적으로 어떻게 돌아가는지 확인함
    - transformer내의 각 행렬과 부분들이 어떤 의미를 하고있는지는 아직 공부중
    - k-fold는?
        - stratified level별로
    - 단순CNN을 Efficientnet으로 바꾸면 좀 더 좋지 않을까
    - augment는 뭐가 좋을까
    - 피어세션 끝나고 기홍님 올려주신 im2latex를 우리 데이터로 시험적으로 돌려보는 것이 오늘 목표!
    - transformer도 여러 버전이 분명히 있고 그 중에서도 성능이 나은 모델이 있지 않을까?
        - 그렇다면 cnn에 sota쓰고 decoder에도 transformer의 sota를 쓰면 좋지 않나?
- 임기홍
    - 손글씨와 인쇄물 구분을 고민중
        - 현재 모델 확인중
- 김현우
    - 앱 확인
    - 콴다
        - 수식 이미지와 유사한 문제집 찾아줌
    - 포토메스(photo math)
        - 인식률이 좋음
    - mathpix
        - test횟수가 제한됨(50)
        - 거의 100%정도
        - 흐릿하고 변형된 이미지도 잘 출력해줌
        - open source가 존재, 확인해볼여부가 있음

### 생각
- (방향) 모델선정하는데 있어 어떤식으로 문제를 정의할까?
    - 이미지 캡셔닝 문제
        - 이미지로부터 text생성
        - SOTA
            - OSCAR
            - M2 Transformer
    - text recognition
        - SOTA
            - SRN
                - 데모는 성능안좋음(paddle)
            - SATRN
- 모델을 기본으로, 데이터에 집중?
- 전처리는 그렇게 중요한거 아닌거같다.
    - augmentation은 그리 큰 영향력이 없을지도..

### 해볼거
- 서버는 반납 ㅠ
    - 돌리고 확인하는건 어려움, submit도 안됨
- 논문 확인해보기
    - srn
    - img2latex
    - 등...
- 내일 멘토님과 방향성 확인하기


### 참고
- [캐글-im2latex](https://www.kaggle.com/shahrukhkhan/im2latex100k?select=formula_images_processed)
- [SOTA-textrecognition](https://paperswithcode.com/sota/scene-text-recognition-on-icdar2013)
- [paddlepaddle](https://www.paddlepaddle.org.cn/hub/scene/ocr)