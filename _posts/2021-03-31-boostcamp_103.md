---
title: "Boostcamp AI Tech (P1 - Day03)"
date: 2021-03-31
layout: post
tags: [Naver Boostcamp, daily report]
use_math: true
---

## 강의
* ### Model
    * Model: "informative representation of system"
    * nn.modules
        * init
        * forward: 모델이 호출되면 자동 실행됨
        * parameters: data, grad, required_grad 등
    * Pretrained model
        * CNN base 모델 구조
        * 내 data, model과 유사성
        * transfer learning
        * [torchvision.models](https://pytorch.org/vision/stable/models.html), [TIM (git)](https://github.com/rwightman/pytorch-image-models)
        * backbone
            * trainable: fine tuning
            * freeze: feature extraction
<br><br>

## Peer session
* 모델 세 개로 나눠서 각각 학습 한 분, 모델 하나에 헤드 세 개로 학습하신 분 만남
    * (보윤님) 마스크 클래스 모델, 성별 클래스 모델, 나이 regression 모델 세 개 나눠서 각각 학습 진행. 하지만 큰 성능 효과를 얻지는 못함.
    * (민용님) Faster-CNN 처럼, 특징 추출은 공통적으로 사용하고, 세 가지 헤드(head)를 나누어 다른 loss로 주며 학습. 
* normalize 값
    * (resnet) pretrained model이 학습될 때 사용했던 mean, std 값대로 보통 normalize 해줌
    * [링크](https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2)
* 일반화
    * 라벨 스무딩
    * 경계값에 있는 (50대) 데이터를 제외하고 학습? (imbalance 문제 해결 + 나이 클래스 특성 경계 확보)
<br><br>

## 개인 Project 진행 상황
* pretrained efficient net 도입
* 학습 속도 지연 문제 해결
    * validation set이 따로 분리되지 않고, train set 전체 범위로 지정되어 있었음.
        * 내가 만든 데이터셋 클래스에 맞게, random.sample 함수만 사용해 사람별(7로 나눈 몫에 해당하는 랜덤 인덱스를 validation mask로 사용) split
    * Dataset 클래스의 getitem 함수를 수정
        * for 문으로 레이블 탐색 후 지정 $\rightarrow$ init 함수에서 매핑 딕셔너리 생성 후 getitem 시 조건에 해당하는 레이블 출력
* transforms 다양화
    * resize(200, 200)
    * random rotation(30)
    * random resize crop(150)
    * random horizontal flip
    * normalize(resnet과 같은 값)
* 텐서보드와 nvidia-smi를 이용해, 실시간으로 학습 상황(train loss, val loss, val acc 변화)과 GPU 가동률 확인
<br><br>