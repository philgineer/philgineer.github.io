<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Wrap-up Report</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.highlight-default {
}
.highlight-gray {
	color: rgb(155,154,151);
}
.highlight-brown {
	color: rgb(100,71,58);
}
.highlight-orange {
	color: rgb(217,115,13);
}
.highlight-yellow {
	color: rgb(223,171,1);
}
.highlight-teal {
	color: rgb(15,123,108);
}
.highlight-blue {
	color: rgb(11,110,153);
}
.highlight-purple {
	color: rgb(105,64,165);
}
.highlight-pink {
	color: rgb(173,26,114);
}
.highlight-red {
	color: rgb(224,62,62);
}
.highlight-gray_background {
	background: rgb(235,236,237);
}
.highlight-brown_background {
	background: rgb(233,229,227);
}
.highlight-orange_background {
	background: rgb(250,235,221);
}
.highlight-yellow_background {
	background: rgb(251,243,219);
}
.highlight-teal_background {
	background: rgb(221,237,234);
}
.highlight-blue_background {
	background: rgb(221,235,241);
}
.highlight-purple_background {
	background: rgb(234,228,242);
}
.highlight-pink_background {
	background: rgb(244,223,235);
}
.highlight-red_background {
	background: rgb(251,228,228);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(55, 53, 47, 0.6);
	fill: rgba(55, 53, 47, 0.6);
}
.block-color-brown {
	color: rgb(100,71,58);
	fill: rgb(100,71,58);
}
.block-color-orange {
	color: rgb(217,115,13);
	fill: rgb(217,115,13);
}
.block-color-yellow {
	color: rgb(223,171,1);
	fill: rgb(223,171,1);
}
.block-color-teal {
	color: rgb(15,123,108);
	fill: rgb(15,123,108);
}
.block-color-blue {
	color: rgb(11,110,153);
	fill: rgb(11,110,153);
}
.block-color-purple {
	color: rgb(105,64,165);
	fill: rgb(105,64,165);
}
.block-color-pink {
	color: rgb(173,26,114);
	fill: rgb(173,26,114);
}
.block-color-red {
	color: rgb(224,62,62);
	fill: rgb(224,62,62);
}
.block-color-gray_background {
	background: rgb(235,236,237);
}
.block-color-brown_background {
	background: rgb(233,229,227);
}
.block-color-orange_background {
	background: rgb(250,235,221);
}
.block-color-yellow_background {
	background: rgb(251,243,219);
}
.block-color-teal_background {
	background: rgb(221,237,234);
}
.block-color-blue_background {
	background: rgb(221,235,241);
}
.block-color-purple_background {
	background: rgb(234,228,242);
}
.block-color-pink_background {
	background: rgb(244,223,235);
}
.block-color-red_background {
	background: rgb(251,228,228);
}
.select-value-color-default { background-color: rgba(206,205,202,0.5); }
.select-value-color-gray { background-color: rgba(155,154,151, 0.4); }
.select-value-color-brown { background-color: rgba(140,46,0,0.2); }
.select-value-color-orange { background-color: rgba(245,93,0,0.2); }
.select-value-color-yellow { background-color: rgba(233,168,0,0.2); }
.select-value-color-green { background-color: rgba(0,135,107,0.2); }
.select-value-color-blue { background-color: rgba(0,120,223,0.2); }
.select-value-color-purple { background-color: rgba(103,36,222,0.2); }
.select-value-color-pink { background-color: rgba(221,0,129,0.2); }
.select-value-color-red { background-color: rgba(255,0,26,0.2); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="398ba348-68bd-4840-b907-0d2b141c9b78" class="page sans"><header><h1 class="page-title">Wrap-up Report</h1></header><div class="page-body"><h3 id="9cb23745-bf7b-443d-90ff-106ce3641ef1" class=""><mark class="highlight-teal">Naver Boostcamp AI Tech</mark></h3><p id="49406803-b2e6-47a5-9abb-f2624d607f7a" class=""><mark class="highlight-gray"><strong>P stage </strong></mark></p><p id="544bab29-52eb-4ec9-80af-7df1b37b70f3" class="">
</p><div id="10b166b8-78f8-491a-8f4c-5243034a0ebe" class="collection-content"><h4 class="collection-title">윤준호 (T1138)</h4><table class="collection-content"><thead><tr><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesTitle"><path d="M7.73943662,8.6971831 C7.77640845,8.7834507 7.81338028,8.8943662 7.81338028,9.00528169 C7.81338028,9.49823944 7.40669014,9.89260563 6.91373239,9.89260563 C6.53169014,9.89260563 6.19894366,9.64612676 6.08802817,9.30105634 L5.75528169,8.33978873 L2.05809859,8.33978873 L1.72535211,9.30105634 C1.61443662,9.64612676 1.2693662,9.89260563 0.887323944,9.89260563 C0.394366197,9.89260563 0,9.49823944 0,9.00528169 C0,8.8943662 0.0246478873,8.7834507 0.0616197183,8.6971831 L2.46478873,2.48591549 C2.68661972,1.90669014 3.24119718,1.5 3.90669014,1.5 C4.55985915,1.5 5.12676056,1.90669014 5.34859155,2.48591549 L7.73943662,8.6971831 Z M2.60035211,6.82394366 L5.21302817,6.82394366 L3.90669014,3.10211268 L2.60035211,6.82394366 Z M11.3996479,3.70598592 C12.7552817,3.70598592 14,4.24823944 14,5.96126761 L14,9.07922535 C14,9.52288732 13.6549296,9.89260563 13.2112676,9.89260563 C12.8169014,9.89260563 12.471831,9.59683099 12.4225352,9.19014085 C12.028169,9.6584507 11.3257042,9.95422535 10.5492958,9.95422535 C9.60035211,9.95422535 8.47887324,9.31338028 8.47887324,7.98239437 C8.47887324,6.58978873 9.60035211,6.08450704 10.5492958,6.08450704 C11.3380282,6.08450704 12.040493,6.33098592 12.4348592,6.81161972 L12.4348592,5.98591549 C12.4348592,5.38204225 11.9172535,4.98767606 11.1285211,4.98767606 C10.6602113,4.98767606 10.2411972,5.11091549 9.80985915,5.38204225 C9.72359155,5.43133803 9.61267606,5.46830986 9.50176056,5.46830986 C9.18133803,5.46830986 8.91021127,5.1971831 8.91021127,4.86443662 C8.91021127,4.64260563 9.0334507,4.44542254 9.19366197,4.34683099 C9.87147887,3.90316901 10.6232394,3.70598592 11.3996479,3.70598592 Z M11.1778169,8.8943662 C11.6830986,8.8943662 12.1760563,8.72183099 12.4348592,8.37676056 L12.4348592,7.63732394 C12.1760563,7.29225352 11.6830986,7.11971831 11.1778169,7.11971831 C10.5616197,7.11971831 10.056338,7.45246479 10.056338,8.0193662 C10.056338,8.57394366 10.5616197,8.8943662 11.1778169,8.8943662 Z M0.65625,11.125 L13.34375,11.125 C13.7061869,11.125 14,11.4188131 14,11.78125 C14,12.1436869 13.7061869,12.4375 13.34375,12.4375 L0.65625,12.4375 C0.293813133,12.4375 4.43857149e-17,12.1436869 0,11.78125 C-4.43857149e-17,11.4188131 0.293813133,11.125 0.65625,11.125 Z"></path></svg></span>Title</th><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesMultipleSelect"><path d="M4,3 C4,2.447715 4.447715,2 5,2 L12,2 C12.5523,2 13,2.447716 13,3 C13,3.55228 12.5523,4 12,4 L5,4 C4.447715,4 4,3.55228 4,3 Z M4,7 C4,6.447715 4.447715,6 5,6 L12,6 C12.5523,6 13,6.447716 13,7 C13,7.55228 12.5523,8 12,8 L5,8 C4.447715,8 4,7.55228 4,7 Z M4,11 C4,10.447715 4.447715,10 5,10 L12,10 C12.5523,10 13,10.447716 13,11 C13,11.55228 12.5523,12 12,12 L5,12 C4.447715,12 4,11.55228 4,11 Z M2,4 C1.44771525,4 1,3.55228475 1,3 C1,2.44771525 1.44771525,2 2,2 C2.55228475,2 3,2.44771525 3,3 C3,3.55228475 2.55228475,4 2,4 Z M2,8 C1.44771525,8 1,7.55228475 1,7 C1,6.44771525 1.44771525,6 2,6 C2.55228475,6 3,6.44771525 3,7 C3,7.55228475 2.55228475,8 2,8 Z M2,12 C1.44771525,12 1,11.5522847 1,11 C1,10.4477153 1.44771525,10 2,10 C2.55228475,10 3,10.4477153 3,11 C3,11.5522847 2.55228475,12 2,12 Z"></path></svg></span>Task</th><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesDate"><path d="M10.8889,5.5 L3.11111,5.5 L3.11111,7.05556 L10.8889,7.05556 L10.8889,5.5 Z M12.4444,1.05556 L11.6667,1.05556 L11.6667,0 L10.1111,0 L10.1111,1.05556 L3.88889,1.05556 L3.88889,0 L2.33333,0 L2.33333,1.05556 L1.55556,1.05556 C0.692222,1.05556 0.00777777,1.75556 0.00777777,2.61111 L0,12.5 C0,13.3556 0.692222,14 1.55556,14 L12.4444,14 C13.3,14 14,13.3556 14,12.5 L14,2.61111 C14,1.75556 13.3,1.05556 12.4444,1.05556 Z M12.4444,12.5 L1.55556,12.5 L1.55556,3.94444 L12.4444,3.94444 L12.4444,12.5 Z M8.55556,8.61111 L3.11111,8.61111 L3.11111,10.1667 L8.55556,10.1667 L8.55556,8.61111 Z"></path></svg></span>Date</th></tr></thead><tbody><tr id="1ab409bf-00cf-4691-8ed8-fb8be626536a"><td class="cell-title"><a href="https://www.notion.so/1ab409bf00cf46918ed8fb8be626536a">수식 인식기</a></td><td class="cell-Z^bT"><span class="selected-value select-value-color-orange">NLP</span><span class="selected-value select-value-color-green">Optical Character Recognition</span></td><td class="cell-;[Kb"><time>@2021/05/24 → 2021/06/18</time></td></tr></tbody></table></div><h3 id="9ebfe97a-9586-4dd5-ae93-a30724b74b95" class=""><mark class="highlight-red">최종 결과 : 0.5639 (팀 순위 7위)</mark></h3><figure id="684c0a97-549f-4ba5-9743-aad1ce526b7f"><a href="https://github.com/bcaitech1/p4-fr-connectnet" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">bcaitech1/p4-fr-connectnet</div><div class="bookmark-description">P stage 4 대회 진행 과정과 결과를 기록한 Team Git repo 입니다. 대회 특성상 수정 혹은 삭제된 부분이 존재 합니다 Ground rule pip install -r requirements.txt git clone https://github.com/bcaitech1/p4-fr-connectnet.git python ./train.py --c config/SATRN.yaml python ./inference.py --checkpoint ./log/satrn/checkpoints/0050.pth</div></div><div class="bookmark-href"><img src="https://github.com/favicon.ico" class="icon bookmark-icon"/>https://github.com/bcaitech1/p4-fr-connectnet</div></div><img src="https://opengraph.githubassets.com/09868657c86189de103d6f169d258c833169c5a20ad25e08081e25d69268c159/bcaitech1/p4-fr-connectnet" class="bookmark-image"/></a></figure>

<figure id="2348089d-ea3e-4789-a318-f8be9dac5960">
    <video muted autoplay loop style="max-width: 100%; display: block;">
        <source src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/ocrec_play_1.mp4" type="video/mp4">
        <strong>Your browser does not support the video tag.</strong>
    </video>
</figure>

<h1 id="016c974f-6496-430f-bc6a-c7d3e5af15d5" class="">&lt;기술적인 도전&gt;</h1><h2 id="915adf9d-8bab-42b3-be46-383deca9db02" class="">1 . 전략 </h2><h3 id="932f0431-3f53-47c1-95ea-422b43693cc0" class="">1.1 <strong>Task 분석과 접근법 도출</strong></h3><ul id="58cd70c4-40a1-498d-89ad-a6b4d0fc8ce2" class="bulleted-list"><li>유사한 task인 Scene Text Recognition을 참조하여 SOTA 논문 분석 및 리뷰</li></ul><ul id="f2fd2f99-8374-4fc9-936c-d18e869de702" class="bulleted-list"><li>동일한 task인 논문을 참고해 베이스라인 아키텍처 수정 방향 논의</li></ul><h3 id="b9956ab2-51fe-48b4-8ad1-1f5e790493b6" class="">1.2 <strong>다양한 실험을 통해 성능 향상 시도</strong></h3><ul id="f0d0dd6d-ff61-499a-b065-4adaaa146a23" class="bulleted-list"><li><strong>하이퍼파라미터 튜닝</strong><ul id="33619652-87bb-4b81-ba03-b3c555e4ba08" class="bulleted-list"><li>SATRN의  hidden dimension, filter dimension증가<ul id="71ae83c9-0ae4-4214-99d7-f8a7c726aa76" class="bulleted-list"><li>0.01의 성능 향상</li></ul></li></ul></li></ul><ul id="eaf976c5-8298-4264-a9b7-eea884621f4b" class="bulleted-list"><li><strong>모델 앙상블</strong></li></ul><ul id="383e5071-7298-4b04-b5a2-6e287109fd28" class="bulleted-list"><li><strong>Penalty 추가</strong><ul id="5981d698-8863-49d9-b336-4e47639e21ee" class="bulleted-list"><li>\frac{1}} 처럼 괄호가 맞지 않지 않는 경우가 발생</li></ul><ul id="cb3640b6-c7fc-4af6-ba8f-dbc910349549" class="bulleted-list"><li>그러나, 이미 토큰단위에서 loss를 계산하기 때문에 2차적으로 stack을 이용해 1 - (짝이 맞는 괄호 쌍 / 전체 괄호 쌍)을 더해줌으로서 일종의 penalty 부여<p id="96d32757-f1e4-450f-9a44-ae58d8d03922" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mn>0.8</mn><mi>C</mi><mi>E</mi><mo>+</mo><mn>0.2</mn><mi>P</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>P</mi><mi>e</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>t</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">Loss = 0.8CE + 0.2 ParenPenalty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">oss</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">0.8</span><span class="mord mathnormal" style="margin-right:0.05764em;">CE</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">0.2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">a</span><span class="mord mathnormal">re</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">e</span><span class="mord mathnormal">na</span><span class="mord mathnormal">lt</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span></span><span>﻿</span></span></p></li></ul></li></ul><ul id="b18278af-8fab-4b73-9703-bc0394515e28" class="bulleted-list"><li><strong>데이터셋 추가</strong><ul id="a0d314b8-9359-4901-a5ce-f2d23d15f863" class="bulleted-list"><li>Aida Dataset을 추가적으로 학습(100000+100000)</li></ul><ul id="1a10e078-790e-453d-8d63-b95c499ab8ae" class="bulleted-list"><li>더 데이터를 추가하려했으나 서버용량 때문에 추가못함 10만개 == 약 12GB</li></ul><ul id="e0136a2e-c56a-4450-87b6-b8840258323d" class="bulleted-list"><li>학습 시간이 오래 걸림</li></ul></li></ul><ul id="442944f3-8f15-4902-bad6-920ef34453dc" class="bulleted-list"><li><strong>Data Augmentation</strong><ul id="ee86aade-48d7-495c-a108-3f4cec5fcb79" class="bulleted-list"><li>Image Binarization<figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="b81a38a5-12f9-4dea-b9b5-aa4a17cc4b9c"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">데이터의 noise가 매우 심하여 최대한 숫자와 배경만 남기는 Adaptive Threshold를 통해 노이즈를 감소</div></figure><figure id="f09449d2-b350-43a7-a340-66bf1104ef46" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.12.31.png"><img style="width:336px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.12.31.png"/></a></figure><p id="05aada78-8274-408d-b287-63ac6f61cd63" class="">Original</p><figure id="62b9d2a3-198d-4d14-9396-424cab3b2957" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled.png"><img style="width:336px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled.png"/></a></figure><p id="7b222ef4-872f-4479-a791-a57f7d29554b" class="">Binarization</p></li></ul><ul id="61ec8322-6a8d-455b-b5fb-0b9734cf32d2" class="bulleted-list"><li>Random Rotation / Affine(Shear)<figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="377e23fe-f680-4166-9ea4-873b33e6eb19"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">다양한 각도에서 촬영된 다양한 필체로 쓰인 손글씨 데이터를 잘 아우르는 분포를 학습할 수 있도록 다양한 변환을 적용</div></figure><figure id="b6906d8b-b849-4eca-9408-ac2717d3200d" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.12.43.png"><img style="width:336px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.12.43.png"/></a></figure><p id="0bed49c4-3fb8-4cbf-a4ce-b3c8b4f75428" class="">Rotation</p><figure id="b0565351-935c-4478-b83c-481998efb543" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.12.51.png"><img style="width:336px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.12.51.png"/></a></figure><p id="1ea2b8ca-546a-4cb5-aaaa-a99eeb6751ab" class="">Shear</p></li></ul><p id="151f0d05-7982-442c-94bb-17d8efb4b4ab" class="">
</p><ul id="8de745d7-559e-4237-88a1-f995b1c68120" class="bulleted-list"><li>ColorJitter (Bright / Contrast)<figure id="662a6d18-f575-49b4-97f4-ace887b4d496" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.13.00.png"><img style="width:336px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.13.00.png"/></a></figure><p id="342cbd30-cc9a-4724-bfe5-393103734ddb" class="">Random Brightness</p><figure id="75489c60-f431-4909-8e3e-bd9b4eba4bd8" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.13.07.png"><img style="width:336px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/2021-06-16_18.13.07.png"/></a></figure><p id="f334b031-054e-480e-8983-56a7b1ed1475" class="">Random Contrast</p></li></ul></li></ul><ul id="85bbf626-55ce-4f58-84f0-3e15411324c3" class="bulleted-list"><li><strong>Outlier Correction</strong><figure id="6c663866-23ab-4872-812b-04d6672f24a0" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%201.png"><img style="width:36px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%201.png"/></a></figure><ul id="ea779332-8e80-4562-9f05-258997924dc9" class="bulleted-list"><li>가로/세로 가 0.75 보다 작은 경우 이미지의 내부의 글자가 세로로 출력되어 있음 </li></ul><figure id="92686048-5689-4230-b495-97801239e73c" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%202.png"><img style="width:384px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%202.png"/></a></figure><ul id="b58daa8c-9b4c-40e6-a918-2b518d03a8ee" class="bulleted-list"><li>데이터의 종횡비 (가로 / 세로)가 0.75이하인 경우, 즉 세로가 지나치게 긴 이미지들은 일괄적으로 시계방향 90도 회전 → 0.051 상승<ul id="241c5c38-71f6-4fff-a201-7a9af448cd84" class="bulleted-list"><li>ex) 종횡비가 0.75 이상, 0.8이하인 데이터<figure id="3183f0e2-b0f5-4e74-8246-f49e90b71edf" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%203.png"><img style="width:120px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%203.png"/></a></figure></li></ul></li></ul></li></ul><p id="70961bcc-ef64-4fe4-b363-5f44bbf67437" class="">
</p><ul id="d479e954-5831-49cc-8dd1-363da4d5ae6c" class="bulleted-list"><li>Vertical Image는 못맞추는걸로...<figure id="9afcca48-64d4-4bd8-9e31-46ecab5d6637" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%204.png"><img style="width:432px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%204.png"/></a></figure></li></ul><ul id="f2aa9f3f-039a-4eae-94bc-c3345c626b46" class="bulleted-list"><li>Model<p id="ccd295a8-6f79-4dc6-9dd2-e612db8eb784" class=""> <a href="https://paperswithcode.com/sota/object-detection-on-coco">Paperswithcode</a> 사이트를 참고해 Scene Text Recognition의 SOTA 모델들을 선택해 테스트 진행</p><ul id="60247f90-ca07-4e5a-9687-520130fbd9e6" class="toggle"><li><details open=""><summary>ScreenShot</summary><figure id="e2e3cb8e-62aa-40df-b5fe-3ed4226973a5" class="image"><a href="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%205.png"><img style="width:1118px" src="Wrap-up%20Report%20f09449d2b35043a7a34066bf1104ef46/Untitled%205.png"/></a></figure></details></li></ul></li></ul><p id="bf2162fc-524f-44fb-901f-a5eb0d773222" class="">
</p><h2 id="1320742b-5dde-41f8-acbe-14a3651083a9" class="">2. 모델 아키텍처 (backbone / encoder  / decoder)</h2><p id="2702df75-b8f4-43b8-829d-8a0f4cb1e130" class=""><strong>1) SATRN</strong><div class="indented"><ul id="e75098ee-5cc6-4f75-8c51-e98765bb348d" class="bulleted-list"><li>DenseNet / Transformer (encoder + decoder)<ul id="1b955d6e-2a72-435e-97b8-c1f41cb27cc6" class="bulleted-list"><li>LB: 0.7888</li></ul><ul id="9c765b0f-20c0-49f2-8100-d2ad2ebfdd37" class="bulleted-list"><li>optimizer : Adam (learning_rate = 5e-4)</li></ul><ul id="3dd0461a-b4ad-45b7-abc7-3189e8b983b3" class="bulleted-list"><li>loss:  CrossEntropyLoss </li></ul><ul id="2fac1213-ff7f-451e-8a21-6395bda68150" class="bulleted-list"><li>hyperparameters : batch : 16, epochs : 50</li></ul><ul id="811a410b-18d7-4eeb-b7e9-c30559f6c093" class="bulleted-list"><li>image_size: (128, 256)</li></ul><ul id="77e64d56-1ce7-4280-be74-7c5f537108df" class="bulleted-list"><li>추가로 시도한 것<ul id="add401d1-dab8-4faa-8b35-1383c7676df0" class="bulleted-list"><li>Dense layer depth 증가</li></ul><ul id="c7cef2fa-7024-4198-8622-d02890d111d9" class="bulleted-list"><li>다양한 Augmentation 적용</li></ul><ul id="e7434fba-7e95-47c5-8cbb-1a45e13644c6" class="bulleted-list"><li>positionalencoding2D 을 adaptive2DpositionEncoder로 개선</li></ul><ul id="7828c788-2db1-41ef-8bbf-7435bc0ba7a5" class="bulleted-list"><li>hidden dimension, filter dimension 증가</li></ul></li></ul></li></ul></div></p><p id="6dc4bf22-3f50-4451-be83-956b64ac94b4" class=""><strong>2) Aster</strong><div class="indented"><ul id="bb18c5a9-1bca-43bd-ba71-a8080afbab5a" class="bulleted-list"><li>CNN / Bi-LSTM / LSTM<ul id="bf150232-9df6-4323-b023-0568e95712b0" class="bulleted-list"><li>LB : 0.7917</li></ul><ul id="0abe43ee-7b4e-46c2-b81e-ef817274866b" class="bulleted-list"><li>loss : CrossEntropy </li></ul><ul id="3f84b7ff-6bed-4900-92b6-e917e6222065" class="bulleted-list"><li>optimizer : Adam (learning_rate = 5e-4)</li></ul><ul id="6d794fef-4691-4a30-98a7-190baad0c5c8" class="bulleted-list"><li>hyperparameters : batch : 32, epochs : 50</li></ul><ul id="abc2d280-9ad2-4270-af3e-02b653b1b06c" class="bulleted-list"><li>image_size: (80, 320)</li></ul><ul id="1fc87b1d-6397-4468-a350-ae151c0c37d2" class="bulleted-list"><li>추가로 시도한 것<ul id="e924aae0-7e68-4e3f-9c7e-a11ce49df8d3" class="bulleted-list"><li>Deformable conv layer<p id="52f0a093-c4e6-47c3-a433-0f63295af9b2" class="">주어진 데이터셋에는 기울어진 수식들이 많이 들어있었음.</p><p id="b7c176e3-20ca-4183-b633-cb3e3f18544d" class="">기존의 논문에서는 STN을 통과하여 이미지를 정렬시킴 → 연산량이 많다 </p><p id="e889c40b-d4e5-4561-823f-5815b8dd1156" class="">마지막 3 block에서 conv layer를 Deformable conv layer로 바꾸어 성능 향상을 봄.</p></li></ul></li></ul></li></ul></div></p><p id="7e92f428-7c20-4114-ba32-aec8b7df4afc" class=""><strong>3) CSTR</strong><div class="indented"><ul id="a9b1cbc5-2e93-4449-b442-67c6838e0192" class="bulleted-list"><li>Naive CNN / CBAM &amp; SADM / Multiple Linear<ul id="648d585f-134e-43fd-bdaf-a469876a15bd" class="bulleted-list"><li>LB : None</li></ul><ul id="55ef6aeb-8781-4c4c-b47b-a47688e1b0eb" class="bulleted-list"><li>Valid Acc : 0.28 ~ 0.31</li></ul><ul id="3206637e-d068-4232-85b0-f2684d1280a9" class="bulleted-list"><li>optimizer : AdaDelta (learning_rate = 0.0 ~ 1.0 CosineAnnealingWarmUp)</li></ul><ul id="2b3c8a75-d27e-4b12-8aea-5d130b18508a" class="bulleted-list"><li>loss : LabelSmooth (ratio = 0.1)</li></ul><ul id="8d57d0c7-a174-49e3-a84a-f206e4047912" class="bulleted-list"><li>hyperparameter : batch 100, epochs : 50</li></ul><ul id="26b46b17-e0ae-4771-a74f-6884f502f39e" class="bulleted-list"><li>image_size : (48, 192)</li></ul><ul id="1be5ad92-b7f2-4479-bb79-b1f54551c7bf" class="bulleted-list"><li>추가로 시도한 것<ul id="ac9c5fe1-9bf9-4212-bcf4-42f4d3065cc7" class="bulleted-list"><li>실험초반 오버피팅 이슈 발생 → dropout(p = 0.1), weight_decay (1e-3) 설정</li></ul><ul id="788b5e53-46a1-49a4-9745-4a65c626a11f" class="bulleted-list"><li>이후 오버피팅은 일어나지 않았으나 성능 이슈 발생</li></ul><ul id="5ce08ed7-7ab1-459f-a881-673095ec7dc6" class="bulleted-list"><li>CNN Layer의 dim을 2배씩 늘려 전체적 파라미터를 2배로 size up → 실패</li></ul></li></ul></li></ul></div></p><p id="9ca300ff-2e86-45cd-aea1-42bfb9b58e55" class="">
</p><h2 id="f7b7dd31-4bd1-4d73-aa25-fe9e29ff340f" class="">3. 앙상블</h2><ul id="5b11e7a7-b704-4cc6-84fa-326d7415c217" class="bulleted-list"><li>서로 다른 방향성을 가진 transformer기반의 Satrn과 attention기반 모델을 앙상블<ul id="7884e8f8-a038-4b2f-8796-cc7ae94b4f4e" class="bulleted-list"><li>SATRN, Attention</li></ul></li></ul><ul id="67bb6a62-5ecc-4108-ba4d-270ee9d2716f" class="bulleted-list"><li>멀티스케일 러닝의 효과를 보기위하 각 모델마다 다른 크기의 이미지입력을 사용</li></ul><ul id="d24f53bd-df5f-4ce1-b939-cca666cd1f3e" class="bulleted-list"><li>서로 다른 seed를 이용하여 서로 다른 train셋으로 학습하는 효과를 이용</li></ul><ul id="56047f60-27de-4480-8259-e2af6d14642e" class="bulleted-list"><li>앙상블1 : SATRN(128,384), SATRN(128,256), Aster(80, 320)<ul id="1df6e940-fdb9-436d-a83e-fe0c7df6ac70" class="bulleted-list"><li>싱글 모델 보다 성능이 떨어짐 (LB : 0.74)</li></ul><ul id="9c10e50d-d0e9-4c28-97d7-2fba2450f732" class="bulleted-list"><li>128, 128 이미지로 동일하게 inference 하여 성능이 떨어졌음</li></ul><ul id="e2709dcc-489a-43e7-9561-447fbf1f3fbf" class="bulleted-list"><li>앙상블1 의 문제점을 보완하기 위해 앙상블 2를 시도</li></ul></li></ul><ul id="4128e1eb-1532-4272-8e8d-f76126c04b6c" class="bulleted-list"><li>앙상블2 : SATRN(128,384), SATRN(128,256), Aster(80, 320) (TTA적용)<ul id="86dbb34b-b0c2-4114-970b-bbe49df2bb3a" class="bulleted-list"><li>입력 이미지를 학습시 입력한 이미지 크기에 맞게 inference </li></ul><ul id="25df9bcb-b849-410c-8cb7-95d5ee7b4207" class="bulleted-list"><li>메모리 폭파 → with torch.no_grad() 넣지 않아 발생한 문제</li></ul></li></ul><ul id="f03210f8-018e-4df8-8bf6-eb085a0dd9a1" class="bulleted-list"><li>앙상블3 : SATRN (128, 256) + Aster(80, 320)<ul id="e79bec63-5960-4383-8ac5-cf39e71ba760" class="bulleted-list"><li>서버 문제 때문에 LB 점수를 알 수 없음</li></ul></li></ul><p id="08cb01e3-ade3-4a11-ab01-cedfea5c22ac" class="">
</p><h2 id="746596fa-0d0a-413a-951f-70040b5fd709" class="">4. 시도했으나 잘 되지 않았던 것들 </h2><ul id="4068a510-bb33-44e4-b032-2b9eaf388fe8" class="bulleted-list"><li>앙상블<ul id="a1a680eb-fdf8-459b-be1e-efc604497b9f" class="bulleted-list"><li>제출방식에 있어 기존방식과 달라 예외를 완벽히 잡지 못함 </li></ul><ul id="aea5f449-1555-4f5a-81af-936bea9ca109" class="bulleted-list"><li>앙상블 1은 모델의 성능이 하락</li></ul><ul id="555a74f9-f785-4826-becb-e29f1e712c46" class="bulleted-list"><li>앙상블2와 앙상블3은 부스트캠프의 서버의 용량문제로 성능 측정 불가</li></ul></li></ul><ul id="a462269e-b634-4ded-8d8b-1796676811f5" class="bulleted-list"><li>새로운 모델 구현<ul id="eb958dd8-7e8d-41fd-8bf0-c75e5b975193" class="bulleted-list"><li>SRN, CSTR 구현 시도</li></ul><ul id="5fd1cfa6-430a-41f0-98d3-4098fbe1f55a" class="bulleted-list"><li>Efficientnetv2 FPN Backbone 구현 시도</li></ul><ul id="e3bad08c-285d-4b68-8abd-5d6f51ed379d" class="bulleted-list"><li>기존 Attention 베이스라인에서 GRU 에러 fix 후 구현 → LSTM과 큰 차이 없음</li></ul></li></ul><ul id="77f4cc74-b864-4f82-9d08-0d52187de570" class="bulleted-list"><li>Beam search<ul id="6f39bd81-1e85-4832-aa52-963ba1f60cf8" class="bulleted-list"><li>RNN, LSTM에 있어 각각 token 단위에서 예측하는 걸 보완해 top k개의 후보를 고려하는 알고리즘인데, 모든 word가 한 번에 입력되고 예측하는 transformer의 경우 성능 향상에 도움이 될지 미지수임</li></ul><ul id="a543c3ac-3898-41e5-b037-c3e7f0c8b0ce" class="bulleted-list"><li>같은 이유로 RNN, LSTM에서와 달리 transformer에서는 token 선택 시 사전 확률 - 사후 확률이 달라지기 때문에 구현 난이도가 상당하고, 한다고 하더라도 연산량이 큰 폭으로 증가함</li></ul></li></ul><ul id="72fae258-884a-4b37-a655-0dc1e403f9bc" class="bulleted-list"><li>시각화<ul id="c717fcb6-1c2a-4d23-8f94-af8bd6e58fe6" class="bulleted-list"><li>attention map을 시각화 하려했지만 못함</li></ul></li></ul><ul id="7553ef2a-b478-4220-86e9-efd6636f4929" class="bulleted-list"><li>데이터셋 추가 <ul id="54ea6922-f2b9-44fe-a8da-9ec3017793a8" class="bulleted-list"><li>Aida dataset을 추가하여 하였으나 점수가 별로 안올라서 포기</li></ul><ul id="70c2044a-2018-4e51-b928-e1465ea2bb81" class="bulleted-list"><li>Im2Latex를 추가하려고 하였으나 서버용량이 부족하여 추가하지 못함</li></ul></li></ul><p id="2dfc40b8-c6c2-43d1-851e-31553beef56e" class="">
</p><h1 id="219f1d37-e8f5-4326-81dc-926a444b6c81" class="">&lt;프로젝트 회고&gt;</h1><p id="0223724f-5f80-4174-a8c6-47d630354296" class="">유사한 테스크의 논문들을 탐색하며, 주어진 베이스라인에서 벗어나 새로운 모델들을 많이 시도해봤다는 점에서 뿌듯한 프로젝트였다. 하지만 결과적으로 가장 좋은 성능이 나온 모델은 베이스라인인 SATRN 아키텍처를 수정한 것이었고, 우리 팀은 (실패한) &quot;모델의 탄생과 죽음&quot;이라는 제목의 발표를 제작하게 되었다. 비록 성능 향상에 영향을 주진 못했지만, 문제를 인식하고 새로운 접근들을 시도한 후 실패한 원인을 분석하면서 많이 성장할 수 있었기 때문이다.</p><p id="6b2edeab-247e-4eef-84c0-df65cdecf387" class="">이번 프로젝트로부터 얻은 가장 큰 교훈은, 아주 유사해보이는 테스크일지라도 SOTA로 검증된 레퍼런스 모델을 가져다 쓸 때는 그 궁합을 철저하게 분석해야한다는 것이다. 텍스트 multi-line recognition에서 아주 좋은 성능을 보이는 CSTR을 구현하고 수식 데이터셋에 적용했지만 성능은 별로 좋지 않았다. 기존 CSTR의 경우 알파벳과 숫자로 37개의 토큰과 25의 문장 최대 길이로 학습되고 예측에 사용된 반면, 수식 데이터셋에는 무려 245개의 토큰과 254의 문장 최대 길이로 학습되고 예측했기 때문에, NLP transformer가 아닌 CNN으로 토큰을 예측하는 CSTR의 모델이 각각 7배, 10 배에 달하는 토큰, 문장 최대 길이의 복잡도를 따라가지 못하고 underfit이 발생한 것으로 해석된다. 대회 성적은 중위권이지만, 성공과 실패를 통해 성장한 지표로는 1등이 아니었나 생각한다.</p><p id="eef702f1-d12c-49c6-8f0a-e70f6eba6bfe" class="">
</p></div></article></body></html>